{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 pset 9 - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "(For this problem, you might want to review the analysis of Fibonacci numbers from section 6.2 of the text.  You can also google \"Fibonacci matrix\" to find lots of similar info online at various levels of sophistication.)\n",
    "\n",
    "Consider the [\"Tetranacci number\" sequence](https://oeis.org/A000078) $t_n$:\n",
    "\n",
    "$$\n",
    "0, 0, 0, 1, 1, 2, 4, 8, 15, 29, 56, 108, 208, 401, 773, 1490, 2872, 5536, 10671, 20569, 39648, 76424, 147312, 283953, 547337\n",
    "$$\n",
    "\n",
    "The first four terms are $t_1,t_2,t_3,t_4 = 0, 0, 0, 1$, and after that each number is the sum of *four* preceding terms:\n",
    "\n",
    "$$\n",
    "t_n = t_{n-4} + t_{n-3} + t_{n-2} + t_{n-1}\n",
    "$$\n",
    "\n",
    "## (a)\n",
    "\n",
    "Write this *recurrence relation* in matrix form $\\vec{t}_n = A \\vec{t}_{n-1}$ where $\\vec{t}_n = (t_n, t_{n-1}, t_{n-2}, t_{n-3})$ for some matrix $A$.\n",
    "\n",
    "Check that you have the right matrix by computing `A^16 * [1,0,0,0]` in Julia and comparing to the sequence terms given above.  (Make sure that you compare to the right terms.  Which terms should this give?)\n",
    "\n",
    "## (b)\n",
    "\n",
    "Find the eigenvalues of $A$ numerically via `eigvals(A)`.  Using these, predict the what the ratio $t_n / t_{n-1}$ tends to for large $n$.\n",
    "\n",
    "Check your answer from numerically by computing `t = big(A)^n * [1,0,0,0]` in Julia to get the $\\vec{t}_{n+4}$ vector for a large-ish $n$, and hence the ratio $t_{n+4} / t_{n+3}$ = `t[1]/t[2]`.   (Doesn't need to be too big because of the exponential growth.  Here, the `big` function is used to tell Julia to switch to slow [arbitrary-precision numbers](https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic) so that you don't run out of digits when $n$ gets big.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "#### (a)\n",
    "We choose the matrix\n",
    "$$A\\begin{pmatrix} 1 & 1 & 1 & 1\\\\ 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 1\\end{pmatrix}$$\n",
    "so that we have\n",
    "$$A\\begin{pmatrix} t_{n+3}\\\\ t_{n+2}\\\\ t_{n+1}\\\\ t_{n}\\end{pmatrix}=\\begin{pmatrix} t_{n+3}+t_{n+2}+t_{n+1}+t_n\\\\ t_{n+3} \\\\ t_{n+2}\\\\ t_{n}\\end{pmatrix} = \\begin{pmatrix} t_{n+4}\\\\ t_{n+3}\\\\ t_{n+2}\\\\ t_{n+1}\\end{pmatrix}\\,.$$\n",
    "If we now check numerically with Julia, $A^{16}\\begin{pmatrix}1\\\\0\\\\0\\\\0\\end{pmatrix}$ should compute $\\begin{pmatrix}t_{20}\\\\t_{19}\\\\t_{18}\\\\t_{17}\\end{pmatrix}=\\begin{pmatrix}20569\\\\10671\\\\5536\\\\2872\\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 20569\n",
       " 10671\n",
       "  5536\n",
       "  2872"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=[1 1 1 1\n",
    "   1 0 0 0\n",
    "   0 1 0 0\n",
    "   0 0 1 0]\n",
    "A^16*[1,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Let us find the eigenvalues of $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Complex{Float64},1}:\n",
       "    1.92756+0.0im     \n",
       " -0.0763789+0.814704im\n",
       " -0.0763789-0.814704im\n",
       "  -0.774804+0.0im     "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the ratio $t_n/t_{n-1}$ to tend to the value of the biggest eigenvalue (in this case 1.92756). In particular, we always approach such problems by writing the initial vector in the basis of the eigenvectors:\n",
    "$$ \\begin{pmatrix} 1\\\\0\\\\0\\\\0\\end{pmatrix} = c_1 v_1+c_2 v_2+c_3 v_3+c_4 v_4$$\n",
    "where $|\\lambda_1|<|\\lambda_2|<|\\lambda_3|<|\\lambda_4|$ are the eigenvalues in order of increasing magnitude, $v_1,\\ldots,v_4$ are the corresponding eigenvectors, and $c_1,\\ldots,c_4$ are some coefficients.  We then have\n",
    "$$\\begin{pmatrix}t_{n+4}\\\\t_{n+3}\\\\t_{n+2}\\\\t_{n+1}\\end{pmatrix}=A^n\\begin{pmatrix}1\\\\0\\\\0\\\\0\\end{pmatrix} = \\lambda_1^n c_1 v_1+\\lambda_2^n c_2 v_2+\\lambda_3^n c_3 v_3+\\lambda_4^n c_4 v_4\\approx \\lambda_4^n c_4 v_4 $$\n",
    "since the $\\lambda_4^n$ term grows exponentially faster than the other three.   If we look at the last component of this vector, we see $t_{n+1}\\approx\\lambda_4^n \\alpha$, where $\\alpha$ is the last component of $c_4 v_4$. Hence\n",
    "$$ \\boxed{ t_{n+1}/t_{n} \\approx (\\lambda_4^n \\alpha)/(\\lambda_4^{n-1}\\alpha) = \\lambda_4=1.92756 }$$\n",
    "for $n\\gg0$.\n",
    "\n",
    "Let us verify this with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.927561975482925303801783836461860202766769057070753895783659858855992063133400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=50\n",
    "t=big(A)^n*[1,0,0,0]\n",
    "t[1]/t[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "(From Strang, section 6.4, problem 18.)\n",
    "\n",
    "Let $A$ be some real rectangular (possibly non-square) matrix.  The block matrix\n",
    "$$S = \\begin{pmatrix} 0 & A \\\\ A^T & 0 \\end{pmatrix}$$\n",
    "is real-symmetric (where \"0\" denotes a block of zeros).  Consider the (real) eigenvalues λ and eigenvectors $x = (y,z)$ of S, satisfying $Sx = \\lambda x$:\n",
    "\n",
    "$$\n",
    "Sx = \\underbrace{\\begin{pmatrix} 0 & A \\\\ A^T & 0 \\end{pmatrix}}_S \\underbrace{\\begin{pmatrix} y \\\\ z \\end{pmatrix}}_x = \\lambda \\begin{pmatrix} y \\\\ z \\end{pmatrix} = \\lambda x\n",
    "$$\n",
    "\n",
    "**(a)** If $A$ is $m\\times n$, how big are the vectors $y$ and $z$, and how big are the two blocks of 0's in $S$?\n",
    "\n",
    "**(b)** Show that $-\\lambda$ is also an eigenvalue, with eigenvector $(y,-z)$.\n",
    "\n",
    "Check this for a random $3\\times 4$ matrix `A = randn(3,4)`, with `S = [ zeros(3,3) A; A' zeros(4,4)]`.  Compute `eigvals(S)`: does it match your prediction?\n",
    "\n",
    "**(c)** Show that $A^TAz = \\lambda^2 z$, so that $\\lambda^2$ is an eigenvalue of $A^T A$.  Check this via `eigvals(A'*A)`.\n",
    "\n",
    "**(d)** If $A = I$ ($2 \\times 2$), find all four eigenvectors and eigenvalues of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "#### (a)\n",
    "If $A$ is $m\\times n$, the dimensions of the two blocks of zeros are $m\\times m$ for the top left one (since it has the same number of rows as $A$) and $n\\times n$ for the bottom right one (since it has the same number of columns as $A$). Similarly $y$ is an $m$-dimensional vector and $z$ is an $n$-dimensional one.\n",
    "#### (b)\n",
    "If $Sx=\\lambda x$, this means that $Az=\\lambda y$ and $A^Ty=\\lambda z$. Hence\n",
    "$$S\\begin{pmatrix} y\\\\ -z\\end{pmatrix} = \\begin{pmatrix}0& A\\\\ A^T & 0\\end{pmatrix}\\begin{pmatrix} y\\\\-z\\end{pmatrix} = \\begin{pmatrix}-Az\\\\ A^Ty\\end{pmatrix}=\\begin{pmatrix} -\\lambda y\\\\ \\lambda z\\end{pmatrix}=-\\lambda\\begin{pmatrix} y\\\\-z\\end{pmatrix}\\,.$$\n",
    "So $-\\lambda$ is an eigenvalue of $S$ with eigenvector $\\begin{pmatrix}y\\\\-z\\end{pmatrix}$. Let us verify this with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       " -4.13035    \n",
       " -1.91185    \n",
       " -1.14518    \n",
       "  8.53459e-16\n",
       "  1.14518    \n",
       "  1.91185    \n",
       "  4.13035    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=randn(3,4)\n",
    "S=[zeros(3,3) A; A' zeros(4,4)]\n",
    "λ=eigvals(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the nonzero eigenvalues (the central eigenvalue is 0 up to machine precision) come in pairs\n",
    "$\\lambda$ and $-\\lambda$. In fact 0 has to be an eigenvalue, since $A$ has 7 eigenvalues and the nonzero ones come in pairs.\n",
    "\n",
    "#### (c)\n",
    "If $\\begin{pmatrix}y\\\\z\\end{pmatrix}$ is an eigenvector of $S$ with eigenvalue $\\lambda$, we have $Az=\\lambda y$ and $A^Ty=\\lambda z$. In particular, $z$ has to be nonzero, since if $z=0$, $y=0$ and $\\begin{pmatrix}y\\\\z\\end{pmatrix}=0$ would not be an eigenvector. So\n",
    "$$ A^TAz = A^T (\\lambda y)=\\lambda^2z$$\n",
    "Hence, since $z\\neq 0$, we have that $\\lambda^2$ is an eigenvalue of $A$ with eigenvector $z$. Let us check it with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.14651e-16,1.31144,3.65518,17.0598],[17.0598,3.65518,1.31144,7.28392e-31,1.31144,3.65518,17.0598])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ²=eigvals(A'*A)\n",
    "λ²,λ.^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we see that the eigenvalues of $A^TA$ are precisely the squares of the eigenvalues of $A$. (Don't be confused by the fact that we get them in a different order; the ordering of the computed eigenvalues is somewhat arbitrary.)\n",
    "#### (d)\n",
    "If $A$ is the $2\\times 2$ identity matrix, the only eigenvalue of $A^TA=I$ is 1. So the possible eigenvalues of $S$ are $\\pm 1$. In fact if $e_1,e_2$ are two eigenvectors of $A^TA$ (for example $\\begin{pmatrix}1\\\\0\\end{pmatrix}$ and $\\begin{pmatrix}0\\\\1\\end{pmatrix}$), we have that\n",
    "$$\\begin{pmatrix} e_1\\\\ Ae_1\\end{pmatrix},\\ \\begin{pmatrix} e_1\\\\ -Ae_1\\end{pmatrix},\\ \\begin{pmatrix}e_2\\\\ Ae_2\\end{pmatrix},\\ \\begin{pmatrix} e_2\\\\ -Ae_2\\end{pmatrix}\\,,$$\n",
    "are eigenvectors of $S$ for 1, -1, 1 and -1 respectively. \n",
    "\n",
    "Let us verify our computation with Julia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -1.0\n",
       " -1.0\n",
       "  1.0\n",
       "  1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=[zeros(2,2) eye(2); eye(2) zeros(2,2)]\n",
    "eigvals(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "(From Strang, section 6.4, problem 33.)\n",
    "\n",
    "Suppose $A^T = -A$, a real *antisymmetric* matrix (also called *skew-symmetric*).   Form a random real antisymmetric $5\\times 5$ matrix in Julia via `A = randn(5,5); A = A - A'`.\n",
    "\n",
    "Explain the following facts about $A$, *and* check each fact numerically for your random `A` matrix:\n",
    "\n",
    "**(a)** $x^T A x = 0$ for every real vector $x$.  (Try `x'*A*x` in Julia with `x = randn(5)`.)\n",
    "\n",
    "**(b)** The eigenvalues of $A$ (`eigvals(A)`) are purely imaginary.\n",
    "\n",
    "**(c)** The determinant of $A$ (`det(A)`) is positive or zero (not negative).\n",
    "\n",
    "**(d)** If you solve $dx/dt = Ax$ for any initial condition $x(0)$, then the length of $x$ is conserved: $\\Vert x(t) \\Vert = \\Vert x(0) \\Vert$ for all $t$.    (In Julia, compare `norm(expm(A*t)*x)` to `norm(x)` for various `t`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "#### (a)\n",
    "Since $x^TAx$ is a $1\\times 1$ matrix, it is equal to its own transpose. But\n",
    "$$ x^TAx=(x^TAx)^T=x^T A^T (x^T)^T = x^T(-A)x=-x^TAx$$\n",
    "So $x^TAx$ is a number that is equal to its own opposite: it can be only zero.\n",
    "\n",
    "Let us verify it with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 3.33067e-16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=randn(5,5); A=A-A';\n",
    "x=randn(5)\n",
    "x'*A*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the result is zero (up to round-off errors).\n",
    "\n",
    "**Alternatively:**  for real vectors, $x^T A x = x \\cdot (Ax) = (Ax) \\cdot x$, since $x \\cdot y = y \\cdot x$ for dot products of real vectors.  But that means $x^T A x = (Ax) \\cdot x = (Ax)^T x = x^T A^T x = -(x^T A x)$, and as above this means it is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "You can prove this very similarly to the proof from class that Hermitian matrices have real eigenvalues.  In particular, suppose we have an eigensolution (possibly complex) $Ax = \\lambda x$.  If we take the dot product with $x$, i.e. multiplying both sides by $x^H$, we have:\n",
    "\n",
    "$$\n",
    "x^H A x = \\lambda x^H x = \\lambda \\Vert x \\Vert^2 \\\\\n",
    "= (A^H x)^H x = -(Ax)^H x = -(\\lambda x)^H x = -\\bar{\\lambda} x^H x = -\\bar{\\lambda} \\Vert x \\Vert^2\n",
    "$$\n",
    "\n",
    "for any matrix with $A^H = -A$ (e.g. real $A$ with $A^T = -A$ as we have here).  But since eigenvectors are nonzero, $\\Vert x \\Vert^2 > 0$ and the above equation implies:\n",
    "\n",
    "$$\n",
    "\\boxed{\\lambda = -\\bar{\\lambda} \\implies \\lambda + \\bar{\\lambda} = 2 \\operatorname{Re} \\lambda = 0}\n",
    "$$\n",
    "\n",
    "which means that $\\lambda$ is purely imaginary (its real part is zero).\n",
    "\n",
    "**Alternative proof**: If $A^H = -A$, then consider the matrix $B = iA$: $B^H = (iA)^H = \\bar{i} A^H = (-i)(-A) = B$, so $B$ is Hermitian.  The eigenvalues of $B$ are therefore purely realy, and since $A = -iB$ it follows that the eigenvalues of $A$ are $-i$ times the (real) eigenvalues of $B$, hence the eigenvalues of $A$ are imaginary.\n",
    "\n",
    "Let's check it in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Complex{Float64},1}:\n",
       "  3.29597e-17+3.81676im \n",
       "  3.29597e-17-3.81676im \n",
       " -1.21431e-17+0.972632im\n",
       " -1.21431e-17-0.972632im\n",
       " -1.88558e-17+0.0im     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, the real parts are zero (the tiny real parts are just rounding errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "The determinant of $A$ is the product of all eigenvalues.  There are two cases:\n",
    "\n",
    "First, if 0 is an eigenvalue of $A$, then $\\det A=0$, which is nonnegative.\n",
    "\n",
    "Second, if 0 is not an eigenvalue, we still know that all nonreal eigenvalues come in complex conjugate pairs (since $A$ is real).  Since all eigenvalues are purely imaginary, all of the eigenvalues come in conjugate pairs. So if\n",
    "$$ \\lambda_1,\\bar\\lambda_1,\\dots,\\lambda_k,\\bar\\lambda_k$$\n",
    "are all the eigenvalues of $A$, arranged in complex conjugate pairs, the determinant of $A$ is\n",
    "$$\\det A = \\lambda_1\\bar\\lambda_1\\cdots\\lambda_k\\bar\\lambda_k = |\\lambda_1|^2\\cdots|\\lambda_k|^2>0$$\n",
    "which is positive, as promised.\n",
    "\n",
    "Let us verify it with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9325781323107414e-16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was zero: because A has an odd size ($5\\times 5$), there are two pairs of conjugate eigenvalues and the remaining (nonpaired) eigenvalue must be zero.  The same is true of any odd size.\n",
    "\n",
    "Let's also try an even-size matrix, which should give a positive determinant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.78553497706216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=randn(6,6); A=A-A';\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "If $\\frac{dx}{dt}=At$, then the solution is $x(t) = e^{At} x(0)$.  Hence:\n",
    "\n",
    "$$\n",
    "\\Vert x(t) \\Vert^2 = x(t)^T x(t) = x(0)^T (e^{At})^T e^{At} x(0) = x(0)^T e^{A^T t} e^{At} x(0) =\n",
    "x(0)^T e^{-A t} e^{At} x(0) = x(0)^T x(0) = \\Vert x(0) \\Vert^2\n",
    "$$\n",
    "\n",
    "as desired.  We have used the fact that $(e^A)^T = e^{A^T}$, which is easily derived from the series expansion $e^A = I + A + A^2/2 +\\cdots$.\n",
    "\n",
    "In fact, this proof shows that $e^{At}$ is a *unitary matrix* (orthogonal matrix) for any $A^H = -A$.\n",
    "\n",
    "**Alternative proof**: Another way to show that something is constant is to show that the derivative is zero, i.e. we can show $d\\Vert x \\Vert/dt = 0$.  We can take the derivative simply by the product rule:\n",
    "$$ \\frac{d\\lVert x\\rVert^2}{dt} = \\frac{ d(x^Tx)}{dt}=\\left(\\frac{dx}{dt}\\right)^Tx + x^T\\frac{dx}{dt}=(Ax)^Tx + x^TAx = (x^TA^Tx)+x^TAx = 0$$\n",
    "where the last equality comes from part (a) and from the fact that both $A$ and $A^T=-A$ are antisymmetric. So the derivative of $\\lVert x\\rVert^2$ is 0, that is the norm squared is a constant function. Hence the norm, its square root, is a constant function too.\n",
    "\n",
    "Let us verify it with Julia for a randomly chosen $t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.906887629744583,2.906887629744583)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=randn(6)\n",
    "t=rand() # random t in [0,1)\n",
    "norm(x), norm(expm(A*t)*x)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
