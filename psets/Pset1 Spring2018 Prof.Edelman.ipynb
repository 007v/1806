{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 Fall 2018 pset 1 (in progress)\n",
    "## (due Wednesday 2/14 at 10:55am by submitting pdf through [Stellar](https://stellar.mit.edu/S/course/18/sp18/18.06/) )\n",
    "\n",
    "This problem set is in the form of a [Julia](http://julialang.org/) *notebook* (using the [Jupyter](http://jupyter.org/)/[IJulia](https://github.com/JuliaLang/IJulia.jl) browser-based interface to interactive programming).  We will be using the Julia language throughout the term for simple computational explorations — practical linear algebra is not about hand computations!\n",
    "\n",
    "You can run this without installing anything by logging in at [JuliaBox](https://juliabox.com/).  Just download the notebook file (a `.ipynb` file) by clicking the download icon at the upper right, then drag it onto the JuliaBox dashboard to upload it there.\n",
    "\n",
    "Some of the problems are pencil-and-paper (we just happen to use the notebook to describe them), and some of them require you to run the code in the notebook to see what happens and then explain it.  To **run the code** in an input cell, **just click on the cell and then type shift-return**; see also the \"Help\" menu in the notebook.  When you submit your pset, you may handwrite or type, but please look over and submit one clearly labeled pdf.  You may find\n",
    "that the Jupyter Download-as-PDF or PrintPreview followed by the Browser Print button is cleaner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Which of these matrix functions  make sense (assume $m \\ne n$)?\n",
    "1. f(x) = W * x      (where W is an m x n matrix, x is a length n vector)\n",
    "1. f(x) = W * x + b   (where W is an m x n matrix, x is a length n vector, b is a length n vector)\n",
    "1. f(x) = W \\* W * x (where W is an m x n matrix, x is a length n vector)\n",
    "1. f(x) = W * x  + b (where W is an m x n matrix, x is a length n vector, b is a length m vector)\n",
    "1. f(x) = x * W     (where W is an m x n matrix, x is a length n vector)\n",
    "1. f(x) = sin.(W \\* x) (where W is an m x n matrix, x is a length n vector and the \".\" means take the sine of element of the vector W*x)\n",
    "1. f(x) = sin.(W) \\* x  (where W is an m x n matrix, x is a length n vector)\n",
    "1. f(x) = σ.(x) where (where σ is the [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) function σ(t) = 1/(1+e^(-t)))\n",
    "\n",
    "<br>\n",
    "The \".\" is usually pronounced \"dot\" but if one thinks \"point\" one might remember it is a \"pointwise\" operation, i.e. applies seperately to every element.\n",
    "<br><br><br><br><br><br><br>\n",
    "Execute the commands in Julia to check your work.  While there will not be any computers on the exams, in the real world people check themselves all the time with a computer. (Shift + **enter** executes and moves to the next cell.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "n = 4\n",
    "W = rand(m,n)\n",
    "x = rand(n)\n",
    "bm = rand(m)\n",
    "bn = rand(n); # final semicolon suppresses printing of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice W is a 2x4 arrray whose elements are Float64 (they have decimals) and it is a \"2\" dimensional **matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice x is a length 4 vector of Float64's and it is a \"1\" dimensional matrix. Humans often conflate a 4 vector with a 4x1 matrix.  Sometimes this is highly productive.  Julia usually makes the distinction between a 4 vector and a 4x1 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W*x + bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W*W*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W*x + bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * W  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin.(W*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin.(W) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"Flux\")\n",
    "using Flux   ### Let's load the Flux package which contains σ, if Flux is not on your computer uncomment the line above once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ.(W*x) # You can type \\sigma+<tab> to get the greek letter sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "σ goes from 0 to 1.  It is known as an activation function in machine learning.\n",
    "You can get help by typing question mark and a function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE WHAT FOLLOWS.  PSET  NOT COMPLETE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 \n",
    "m = Dense(identity, rand(n,n), zeros(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "m = Dense(identity, rand(n,n), zeros(n))\n",
    "x = rand(n)\n",
    "@benchmark m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20_000\n",
    "m = Dense(identity, rand(n,n), zeros(n))\n",
    "x = rand(n)\n",
    "@benchmark m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "W = rand(0:2,n,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[W*x1, W*x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W*[x1 x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x->W*x\n",
    "f.([x1,x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Dense(identity,W,zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.([x1,x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to start out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1 1 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Dense(identity,w,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = rand(3); y1=m(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = rand(3); y2=m(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = rand(3); y3=m(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x1 x2 x3]'\\[y1[1], y2[1], y3[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[x1 x2 x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[y1; y2; y3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## in the real world, we use gradient descent to find the parameters w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x,y) = Flux.mse(m(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which Flux.mse(rand(3),rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss, (X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x1 x2 x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Dense(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(Flux.params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=m(x1).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=m(x2).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3=m(x3).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss, Iterators.repeated(([x1,x2,x3],[y1 y2 y3]),3),opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m ... a model we think of as known to nature but not to humans\n",
    "m = Dense(3,1)\n",
    "println( (m.W).data,\": <== neuron we want to learn\" )\n",
    "\n",
    "# We will learn from data inputs (the columns of X) and outputs (the elements of y)\n",
    "X = rand(3,3)\n",
    "y = m(X).data\n",
    "println( y/X, \": <== learned through Gaussian elimination\" )\n",
    "\n",
    "# t ... a model to be learned to fit the data\n",
    "t = Dense(3,1)\n",
    "println((m2.W).data,\"  : <== guess before training\")\n",
    "loss(x,y) = Flux.mse(t(x),y)\n",
    "opt = ADAM(Flux.params(t)[1:1])\n",
    "Flux.train!(loss, Iterators.repeated( (X,y), 10000), opt)\n",
    "println((t.W).data, \" : <== estimate after training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.params(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
